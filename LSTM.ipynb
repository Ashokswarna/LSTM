{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ashok.swarna\\\\OneDrive - Accenture\\\\cenlar'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file():\n",
    "    \n",
    "    df = pd.read_excel('external_regressors.xlsx')\n",
    "    df.head()\n",
    "    df.reset_index(drop=True)\n",
    "    df = df.set_index('Date')\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    cols = df.columns\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_real():\n",
    "    \n",
    "    df = pd.read_excel('External_regressors_Auto.xlsx')\n",
    "    df.head()\n",
    "    df.reset_index(drop=True)\n",
    "    df = df.set_index('Date')\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    cols = df.columns\n",
    "    \n",
    "    return df, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = load_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>HPI</th>\n",
       "      <th>EMPL_non_farm_Employment</th>\n",
       "      <th>arm_adjustable_rates</th>\n",
       "      <th>population(Millions)</th>\n",
       "      <th>30_year_Interest_rate_Mortgage</th>\n",
       "      <th>armrate</th>\n",
       "      <th>r-mortg</th>\n",
       "      <th>spread-mortg</th>\n",
       "      <th>1_year_Treasury</th>\n",
       "      <th>10_years_Treasury</th>\n",
       "      <th>treasury_Difference(Spread_treas)</th>\n",
       "      <th>unemploymet_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>2017</td>\n",
       "      <td>184.770</td>\n",
       "      <td>145695</td>\n",
       "      <td>3.24</td>\n",
       "      <td>324.22</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>2.211364</td>\n",
       "      <td>1.533944</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-01</th>\n",
       "      <td>2017</td>\n",
       "      <td>185.138</td>\n",
       "      <td>145836</td>\n",
       "      <td>3.20</td>\n",
       "      <td>324.36</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>2.298000</td>\n",
       "      <td>1.583714</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-01</th>\n",
       "      <td>2017</td>\n",
       "      <td>186.642</td>\n",
       "      <td>145963</td>\n",
       "      <td>3.21</td>\n",
       "      <td>324.50</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>2.481739</td>\n",
       "      <td>1.739804</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-01</th>\n",
       "      <td>2017</td>\n",
       "      <td>188.649</td>\n",
       "      <td>146176</td>\n",
       "      <td>3.15</td>\n",
       "      <td>324.64</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.182500</td>\n",
       "      <td>1.515833</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>2017</td>\n",
       "      <td>190.652</td>\n",
       "      <td>146304</td>\n",
       "      <td>3.12</td>\n",
       "      <td>324.79</td>\n",
       "      <td>4.01</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>2.203478</td>\n",
       "      <td>1.461543</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Year      HPI  EMPL_non_farm_Employment  arm_adjustable_rates  \\\n",
       "Date                                                                        \n",
       "2017-01-01  2017  184.770                    145695                  3.24   \n",
       "2017-02-01  2017  185.138                    145836                  3.20   \n",
       "2017-03-01  2017  186.642                    145963                  3.21   \n",
       "2017-04-01  2017  188.649                    146176                  3.15   \n",
       "2017-05-01  2017  190.652                    146304                  3.12   \n",
       "\n",
       "            population(Millions)  30_year_Interest_rate_Mortgage  armrate  \\\n",
       "Date                                                                        \n",
       "2017-01-01                324.22                            4.15     4.20   \n",
       "2017-02-01                324.36                            4.17     4.12   \n",
       "2017-03-01                324.50                            4.20     4.09   \n",
       "2017-04-01                324.64                            4.05     4.19   \n",
       "2017-05-01                324.79                            4.01     4.19   \n",
       "\n",
       "            r-mortg  spread-mortg  1_year_Treasury  10_years_Treasury  \\\n",
       "Date                                                                    \n",
       "2017-01-01     4.15          0.05         0.670000           2.211364   \n",
       "2017-02-01     4.17          0.05         0.714286           2.298000   \n",
       "2017-03-01     4.20          0.11         0.741935           2.481739   \n",
       "2017-04-01     4.05          0.14         0.666667           2.182500   \n",
       "2017-05-01     4.01          0.18         0.741935           2.203478   \n",
       "\n",
       "            treasury_Difference(Spread_treas)  unemploymet_rate  \n",
       "Date                                                             \n",
       "2017-01-01                           1.533944               4.7  \n",
       "2017-02-01                           1.583714               4.7  \n",
       "2017-03-01                           1.739804               4.4  \n",
       "2017-04-01                           1.515833               4.4  \n",
       "2017-05-01                           1.461543               4.4  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, col = load_file_real()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Forecast_key', 'Value_for_forecast_key'], dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lstm(X_train, Y_train, X_test, Y_test ):\n",
    "    #n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], Y_train.shape[1]\n",
    "#fit LSTM\n",
    "    #model = Sequential()\n",
    "    #model.add(LSTM(300, activation='relu', input_shape=(X_train.shape[0], X_train.shape[1]),return_sequences = True))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(LSTM(300))\n",
    "    #model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "    #model.compile(optimizer='adam', loss='mse')\n",
    "# define model input_shape=(X_train.shape[0],X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "#define model\n",
    " #   n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], Y_Train.shape[1]\n",
    "# define model\n",
    "    #model = Sequential()\n",
    "    #model.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    #model.add(Dense(100, activation='relu'))\n",
    "    #model.add(Dense(n_outputs))\n",
    "    #model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# fitting the model\n",
    "    model.fit(X_train, Y_train, epochs=10, batch_size=10)\n",
    "\n",
    "    train_pred = model.predict(X_train, verbose=0)\n",
    "    test_pred = model.predict(X_test, verbose=0)\n",
    "\n",
    "    #train_pred.plot(marker=\"o\", color='blue')\n",
    "    #X_train.plot(color='black', marker=\"o\", legend=True)\n",
    "    #plt.show()\n",
    "    #print(train_pred,test_pred )\n",
    "    return model, train_pred, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_test, test_pred):\n",
    "    \n",
    "    MSE =mean_squared_error(y_true=y_test, y_pred=test_pred)                \n",
    "    MAE = mean_absolute_error(y_true=y_test, y_pred=test_pred)\n",
    "    MAPE = mean_absolute_percentage_error(y_test, test_pred)\n",
    "\n",
    "    return MSE, MAE, MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    dff = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(dff.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(dff.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the unique codes for filtering the over all data    \n",
    "forecast_group = df.groupby('Forecast_key', as_index=False)\n",
    "forecast_list = forecast_group.groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 13s 486ms/step - loss: 7.7160\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 798us/step - loss: 7.6241\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 745us/step - loss: 7.5327\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 862us/step - loss: 7.4409\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 7.3520\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 775us/step - loss: 7.2618\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 679us/step - loss: 7.1728\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 697us/step - loss: 7.0854\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 656us/step - loss: 6.9972\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 798us/step - loss: 6.9117\n",
      "10_years_Treasury\n",
      "train 6.850643 2.6018918 103.6816954612732\n",
      "test 4.249764 2.0383043 104.80504035949707\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 13s 486ms/step - loss: 0.6322\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 899us/step - loss: 0.6023\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 727us/step - loss: 0.5733\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 856us/step - loss: 0.5451\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5177\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.4911\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 808us/step - loss: 0.4656\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 819us/step - loss: 0.4408\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 636us/step - loss: 0.4170\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 856us/step - loss: 0.3940\n",
      "1_year_Treasury\n",
      "train 0.37833333 0.61450005 86.31759285926819\n",
      "test 0.38773355 0.6221123 86.46274209022522\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 14s 518ms/step - loss: 13.5846\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 798us/step - loss: 13.3797\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 13.1745\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 627us/step - loss: 12.9705\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 860us/step - loss: 12.7720\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 980us/step - loss: 12.5734\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 12.3765\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 12.1834\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.9903\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 908us/step - loss: 11.7990\n",
      "30_year_Interest_rate_Mortgage\n",
      "train 11.66654 3.4017735 79.42360043525696\n",
      "test 8.67404 2.9386513 76.98444724082947\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 14s 511ms/step - loss: 21951787538.9630\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 769us/step - loss: 21951785490.9630\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 855us/step - loss: 21951781243.2593\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 21951776616.2963\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 945us/step - loss: 21951771230.8148\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 871us/step - loss: 21951768803.5556\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 966us/step - loss: 21951764176.5926\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 965us/step - loss: 21951759170.3704\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 866us/step - loss: 21951755681.1852\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 762us/step - loss: 21951752116.1482\n",
      "EMPL_non_farm_Employment\n",
      "train 21951750000.0 148152.58 99.99979734420776\n",
      "test 22937336000.0 151450.39 99.99979138374329\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 15s 539ms/step - loss: 39421.9831\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 859us/step - loss: 39409.8981\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 837us/step - loss: 39397.8129\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 726us/step - loss: 39385.7176\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 805us/step - loss: 39373.7089\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 833us/step - loss: 39361.6447\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 646us/step - loss: 39349.5794\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 765us/step - loss: 39337.5058\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 39325.4466\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 996us/step - loss: 39313.3740\n",
      "HPI\n",
      "train 39304.926 198.13782 100.07859468460083\n",
      "test 44493.45 210.93028 100.07374286651611\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 14s 530ms/step - loss: 15.4028\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 553us/step - loss: 15.0744\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 496us/step - loss: 14.7533\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 715us/step - loss: 14.4396\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 603us/step - loss: 14.1221\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 518us/step - loss: 13.8187\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 657us/step - loss: 13.5117\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 598us/step - loss: 13.2112\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 537us/step - loss: 12.9155\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 651us/step - loss: 12.6262\n",
      "arm_adjustable_rates\n",
      "train 12.422851 3.5080028 98.79558682441711\n",
      "test 11.94483 3.4533467 98.78616333007812\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 12s 460ms/step - loss: 12.2360\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 480us/step - loss: 11.9930\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 628us/step - loss: 11.7527\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 480us/step - loss: 11.5146\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 554us/step - loss: 11.2795\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 480us/step - loss: 11.0474\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 591us/step - loss: 10.8178\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 517us/step - loss: 10.5917\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 554us/step - loss: 10.3693\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 518us/step - loss: 10.1497\n",
      "armrate\n",
      "train 9.997102 3.159703 77.5734543800354\n",
      "test 9.090575 3.0146234 76.75986886024475\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 7s 246ms/step - loss: 106126.3096\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 443us/step - loss: 106102.0101\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 554us/step - loss: 106077.7376\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 591us/step - loss: 106053.4595\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 554us/step - loss: 106029.1956\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 554us/step - loss: 106004.9045\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 553us/step - loss: 105980.6560\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 517us/step - loss: 105956.3935\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 517us/step - loss: 105932.1293\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 445us/step - loss: 105907.8773\n",
      "population_Millions\n",
      "train 105890.81 325.40607 99.7080385684967\n",
      "test 107732.26 328.22574 99.7105360031128\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 7s 265ms/step - loss: 19.0198\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 554us/step - loss: 18.7766\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 776us/step - loss: 18.5342\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 591us/step - loss: 18.2943\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 553us/step - loss: 18.0560\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 517us/step - loss: 17.8187\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 591us/step - loss: 17.5840\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 517us/step - loss: 17.3511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 554us/step - loss: 17.1214\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 554us/step - loss: 16.8914\n",
      "r-mortg\n",
      "train 16.732964 4.0790296 95.33835649490356\n",
      "test 13.113159 3.6159081 94.78576183319092\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 7s 249ms/step - loss: 15.4808\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 554us/step - loss: 15.1368\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 739us/step - loss: 14.7970\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 480us/step - loss: 14.4602\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 480us/step - loss: 14.1293\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 443us/step - loss: 13.8042\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 517us/step - loss: 13.4808\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 554us/step - loss: 13.1652\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 517us/step - loss: 12.8530\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 554us/step - loss: 12.5481\n",
      "unemploymet_rate\n",
      "train 12.333844 3.5008743 85.47639846801758\n",
      "test 9.227377 3.0368533 83.68667960166931\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "for forecast_item in forecast_list:\n",
    "    df1 = df[df['Forecast_key'].isin ([forecast_item])]\n",
    "    df1=df1.sort_index()\n",
    "    df3 = load_file()\n",
    "    df3 = df3.astype('float32')\n",
    "# normalize features\n",
    "    #scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    #scaled = scaler.fit_transform(df3)\n",
    "# frame as supervised learning\n",
    "   # reframed = series_to_supervised(scaled, 1, 1)\n",
    "   # reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
    "   # print(reframed.head())\n",
    "   # print(reframed.head())\n",
    "    #df3.drop([forecast_item], axis =1, inplace = True)\n",
    "    df4 = df3[forecast_item]\n",
    "    \n",
    "    X_train, X_test = df3[:27], df3[27:34]\n",
    "    Y_train, Y_test = df4[:27], df4[27:34]\n",
    "    X_train = X_train.to_numpy()\n",
    "    X_test = X_test.to_numpy()\n",
    "    Y_train = Y_train.to_numpy()\n",
    "    Y_test = Y_test.to_numpy()\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "   # print(X_train.shape)\n",
    "   # print(Y_train.shape)\n",
    "    model, train_pred, test_pred = fit_lstm(X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "    train_mse, train_mae, train_mape = metrics(Y_train, train_pred)\n",
    "    test_mse, test_mae, test_mape = metrics(Y_test, test_pred)\n",
    "    print(forecast_item)\n",
    "    print('train',train_mse, train_mae, train_mape )\n",
    "    print('test',test_mse, test_mae, test_mape )\n",
    "#    df3 = create_data_frame(df1, train, test, linear_pred_tr,tr_linear_mape, expo_pred_tr,tr_expo_mape,add_pred_tr, tr_add_mape ,linear_pred_te,te_linear_mape,expo_pred_te,te_expo_mape,add_pred_te,te_add_mape)\n",
    "#    df2 = pd.concat([df2,df3], ignore_index = True)\n",
    "\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
